{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo Data Processing\n",
    "\n",
    "Testing the performance of various feature configurations when using DeltaMART with the Yahoo LETOR dataset (train/validation/test split):\n",
    "\n",
    "https://github.com/QingyaoAi/Unbiased-Learning-to-Rank-with-Unbiased-Propensity-Estimation\n",
    "\n",
    "Only using a small subset of queries (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils  # To load Yahoo dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.special import expit  # Logistic function\n",
    "from rank_metrics import ndcg_at_k, mean_average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data\n",
    "\n",
    "#### Features: train.feature\n",
    "\n",
    "Description: \"test_2_5\" means the 5th document for the query with identifier \"2\" in the original test set of the Yahoo letor data.\n",
    "\n",
    "Interpretation: first value is test_queryNum_docNum, rest are feature values (svm_light format?)\n",
    "\n",
    "****\n",
    "\n",
    "#### Labels: train.weights\n",
    "\n",
    "Description: The annotated relevance value for documents in the initial list of each query.\n",
    "\n",
    "Interpretation: first value is queryNum (query_id), rest are labels for URLs at corresponding indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_utils.read_data(data_path='/Users/Ashtekar15/Desktop/Thesis/MGBoost/other/test_data/generate_dataset/',\n",
    "                            file_prefix='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for validation set\n",
    "\n",
    "**dids** (71083): valid_19945_15..., stores query/URL id info\n",
    "\n",
    "**qids** (2994): stores query id info\n",
    "\n",
    "**features** (71083): list of lists, each sublist is a given query/URL pair (sublist len 700)\n",
    "\n",
    "**gold_weights** (2994): list of lists, each sublist is the labels for URLs of a single query (sublist len varies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29921"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num queries in train/val/test (should be 29921)\n",
    "19944 + 2994 + 6983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.723124749298034, 18.310095072710077, 1, 139)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get info on number of URLs/query\n",
    "lls = []\n",
    "\n",
    "for ls in data.gold_weights:\n",
    "    lls.append(len(ls))\n",
    "\n",
    "np.mean(lls), np.std(lls), min(lls), max(lls),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7563852547382973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve for num_queries\n",
    "num_queries = 10\n",
    "\n",
    "mean = np.mean(lls)\n",
    "\n",
    "# (Estimated) total size in GB with given num_queries\n",
    "(700 * 3) * (mean ** 2) * num_queries * 64 / (10 ** 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407.1892096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get total number of values FOR ENTIRE TRAIN SET thru feature generation\n",
    "total = 0\n",
    "for ls in data.gold_weights:\n",
    "    total += (700 * 3) * (len(ls) ** 2)\n",
    "\n",
    "# Estimation of total size in GB\n",
    "(total * 64) / (10 ** 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "- Convert np arrays to np.float32 (?)\n",
    "    - To save memory/use more training data\n",
    "- Choose 10 queries randomly\n",
    "    - Use seed\n",
    "- Get features and labels corresponding to these queries\n",
    "    - Include query id in features (?)\n",
    "    - data.features, data.goldlist\n",
    "- Generate pairwise features\n",
    "    - Include option for delta_features\n",
    "- Build model/make predictions on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to np arrays for faster access\n",
    "\n",
    "# String\n",
    "dids = np.array(data.dids)\n",
    "\n",
    "# String -> int\n",
    "qids = np.array(data.qids, dtype=int)\n",
    "\n",
    "# float64 -> float32\n",
    "features = np.array(data.features, dtype=np.float32)\n",
    "\n",
    "# Since not all sublists of same size\n",
    "gold_weights = np.array([np.array(x, dtype=np.float32) for x in data.gold_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SET SEED FOR RANDOM QUERY SELECTION HERE \"\"\"\n",
    "np.random.seed(1)\n",
    "\n",
    "# Randomly select 10 queries\n",
    "q_choice = np.random.choice(qids, size=10)\n",
    "\n",
    "# Get query id aligned with features\n",
    "query_id = np.array([int(ele.split(\"_\")[1]) for ele in dids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant queries, features, and labels\n",
    "q_rel = query_id[np.isin(query_id, q_choice)]\n",
    "feat_rel = features[np.isin(query_id, q_choice)]\n",
    "label_rel = gold_weights[np.isin(qids, q_choice)]\n",
    "\n",
    "# Join subarrays\n",
    "label_rel = np.concatenate(label_rel)\n",
    "\n",
    "# Include query id in features\n",
    "feat_rel = np.hstack((q_rel.reshape(-1, 1), feat_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to free up memory\n",
    "del data, dids, qids, features, gold_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SET DELTA FEATURES HERE \"\"\"\n",
    "delta_features = False\n",
    "\n",
    "n_rows = 0\n",
    "max_diff = 4\n",
    "n_features = 700\n",
    "\n",
    "# Find max possible number of rows: n_queries * (n_urls_per_query ^ 2) * max_repeat_factor\n",
    "for qid in q_choice:\n",
    "    n_rows += (np.sum(np.isin(q_rel, qid)) ** 2) * max_diff\n",
    "    \n",
    "# Add extra set of columns if delta_features, + 2 for (query_id, label)\n",
    "if delta_features:\n",
    "    n_columns = (n_features * 3) + 2\n",
    "else:\n",
    "    n_columns = (n_features * 2) + 2\n",
    "\n",
    "# Create array to fill in later (faster), step thru with idx\n",
    "features = np.full(shape=(n_rows, n_columns), fill_value=np.nan)\n",
    "idx = 0\n",
    "\n",
    "# Iter thru queries\n",
    "for progress, qid in enumerate(q_choice):\n",
    "    \n",
    "    temp_feat = feat_rel[np.isin(q_rel, qid)]\n",
    "    temp_label = label_rel[np.isin(q_rel, qid)]\n",
    "    \n",
    "    m = temp_feat.shape[0]\n",
    "    \n",
    "    # First URL\n",
    "    for i in range(m):\n",
    "        \n",
    "        # Second URL\n",
    "        for j in range(m):\n",
    "            \n",
    "            label_diff = temp_label[i] - temp_label[j]\n",
    "            \n",
    "            # Repeat importance: duplicate row |label_diff| times in next loop\n",
    "            end_k = int(abs(label_diff)) + 1\n",
    "\n",
    "            for k in range(end_k):\n",
    "\n",
    "                # Delta features: for feature (a, b), represent as (a, b, a-b)\n",
    "                # Format: (qid, feat[i], feat[j], feat[i] - feat[j], label_diff)\n",
    "                if delta_features:\n",
    "                    new_row = np.hstack((temp_feat[i], \n",
    "                                         temp_feat[j, 1:], \n",
    "                                         temp_feat[i, 1:] - temp_feat[j, 1:],\n",
    "                                         label_diff))\n",
    "                else:\n",
    "                    new_row = np.hstack((temp_feat[i], \n",
    "                                         temp_feat[j, 1:], \n",
    "                                         label_diff))\n",
    "\n",
    "                features[idx] = new_row\n",
    "                idx += 1\n",
    "\n",
    "    print(progress + 1)\n",
    "    \n",
    "# Originally allocated array is likely too large, only save relevant rows\n",
    "features = features[~np.isnan(features[:, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
