{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo Data Processing\n",
    "\n",
    "Testing the performance of various feature configurations when using DeltaMART with the Yahoo LETOR dataset (train/validation/test split):\n",
    "\n",
    "https://github.com/QingyaoAi/Unbiased-Learning-to-Rank-with-Unbiased-Propensity-Estimation\n",
    "\n",
    "Only using a small subset of queries (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: train.feature\n",
    "\n",
    "Description: \"test_2_5\" means the 5th document for the query with identifier \"2\" in the original test set of the Yahoo letor data.\n",
    "\n",
    "Interpretation: first value is test_queryNum_docNum, rest are feature values (svm_light format?)\n",
    "\n",
    "****\n",
    "\n",
    "### Labels: train.weights\n",
    "\n",
    "Description: The annotated relevance value for documents in the initial list of each query.\n",
    "\n",
    "Interpretation: first value is queryNum (query_id), rest are labels for URLs at corresponding indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.special import expit  # Logistic function\n",
    "from rank_metrics import ndcg_at_k\n",
    "\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_utils.read_data(data_path='/Users/Ashtekar15/Desktop/Thesis/MGBoost/other/test_scripts/ranking/generate_dataset/',\n",
    "                            file_prefix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dids** (71083): valid_19945_15..., stores query/URL id info\n",
    "\n",
    "**qids** (2994): stores query id info\n",
    "\n",
    "**features** (71083): list of lists, each sublist is a given query/URL pair\n",
    "\n",
    "**gold_weights** (2994): list of lists, each sublist is the labels for URLs of a single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29921"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num queries in train/val/test (should be 29921)\n",
    "19944 + 2994 + 6983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6983, 6983)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.qids), len(data.gold_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473134, 700)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.features), len(data.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473134, 473134)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for ls in data.gold_weights:\n",
    "    total += len(ls)\n",
    "total, len(data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37612331400"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get total number of values thru feature generation\n",
    "total = 0\n",
    "for ls in data.gold_weights:\n",
    "    total += (700 * 3) * (len(ls) ** 2)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407.1892096"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimation of total size in GB\n",
    "(total * 64) / (10 ** 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(filepath, n_queries=30, seed=1):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # For reproducible results from randomly selecting queries\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    df = pd.read_csv(filepath,\n",
    "                     sep=' ',\n",
    "                     header=None)\n",
    "    \n",
    "    # Remove last column of NaN\n",
    "    df = df.iloc[:, :-1]\n",
    "    \n",
    "    # First column: hand-labeled score, second column: query id\n",
    "    df = df.rename(columns={0: 'label', 1: 'query_id'})\n",
    "    \n",
    "    # Get random sample of queries\n",
    "    qids = df.query_id.unique()\n",
    "    qids = np.random.choice(qids, size=n_queries)\n",
    "    \n",
    "    # Only save dataframe with queries of interest\n",
    "    df = df[df.query_id.isin(qids)]\n",
    "    \n",
    "    # Save hand-labels\n",
    "    labels = df.label\n",
    "\n",
    "    # Use regex to get number after colon for every column other than label\n",
    "    features = df.iloc[:, 1:].applymap(lambda x: float(re.findall(r':(.*)', x)[0]))\n",
    "\n",
    "    # Put features and labels in same dataframe\n",
    "    df = features\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, repeat_importance, two_sided, delta_features):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    n_rows = 0\n",
    "    max_diff = 4\n",
    "    n_features = 136\n",
    "    \n",
    "    # Find max possible number of rows: n_queries * (n_urls_per_query ^ 2) * max_repeat_factor\n",
    "    for qid in df.query_id.unique():\n",
    "        urls_per_query = df[df.query_id == qid].shape[0]\n",
    "        \n",
    "        # If not repeating importance, then every query-URL pair only appears once\n",
    "        if repeat_importance:\n",
    "            n_rows += (urls_per_query ** 2) * max_diff\n",
    "        else:\n",
    "            n_rows += (urls_per_query ** 2)\n",
    "    \n",
    "    # Add extra set of columns if delta_features, + 4 for i, j, query_id, label\n",
    "    if delta_features:\n",
    "        n_columns = n_features * 3 + 4\n",
    "    else:\n",
    "        n_columns = n_features * 2 + 4\n",
    "    \n",
    "    # Create array to fill in later (faster)\n",
    "    features = np.full(shape=(n_rows, n_columns), fill_value=np.nan)\n",
    "    idx = 0\n",
    "    \n",
    "    # Compare each URL for a given query\n",
    "    for progress, qid in enumerate(df.query_id.unique()):\n",
    "        \n",
    "        # tdf: temporary dataframe, m: number of URLs in tdf\n",
    "        tdf = df[df.query_id == qid]\n",
    "        m = tdf.shape[0]\n",
    "        \n",
    "        # First URL\n",
    "        for i in range(m):\n",
    "            \n",
    "            # Two sided: feature (a, b) will be repeated later as feature (b, a)\n",
    "            if two_sided:\n",
    "                start_j = 0\n",
    "            else:\n",
    "                start_j = i\n",
    "            \n",
    "            # Second URL\n",
    "            for j in range(start_j, m):\n",
    "                \n",
    "                label_diff = tdf.label.iloc[i] - tdf.label.iloc[j]\n",
    "                \n",
    "                # Repeat importance: duplicate row |label_diff| times\n",
    "                if repeat_importance:\n",
    "                    end_k = int(abs(label_diff)) + 1\n",
    "                else:\n",
    "                    end_k = 1\n",
    "                    \n",
    "                for k in range(end_k):\n",
    "                    \n",
    "                    # Delta features: for feature (a, b), represent as (a, b, a-b)\n",
    "                    # Format: (i, j, query_id, URLi, URLj, URLi-URLj (?), label_diff)\n",
    "                    if delta_features:\n",
    "                        new_row = np.hstack((i,\n",
    "                                             j,\n",
    "                                             qid,\n",
    "                                             tdf.iloc[i, 1:-1], \n",
    "                                             tdf.iloc[j, 1:-1], \n",
    "                                             tdf.iloc[i, 1:-1] - tdf.iloc[j, 1:-1],  \n",
    "                                             label_diff))\n",
    "                    else:\n",
    "                            new_row = np.hstack((i,\n",
    "                                                 j,\n",
    "                                                 qid,\n",
    "                                                 tdf.iloc[i, 1:-1], \n",
    "                                                 tdf.iloc[j, 1:-1],  \n",
    "                                                 label_diff))\n",
    "                        \n",
    "                    features[idx] = new_row\n",
    "                    idx += 1\n",
    "\n",
    "        print(progress)\n",
    "    \n",
    "    # Originally allocated array is likely too large, only save relevant rows\n",
    "    features = features[~np.isnan(features[:, 0])]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(features, df):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # Features does not include i, j, does includes query_id\n",
    "    X = features[:, 2:-1]\n",
    "    y = features[:, -1]\n",
    "\n",
    "    # Same parameters for all calls to ensure consistency\n",
    "    xgbr = XGBRegressor(max_depth=6, \n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=100, # Change to make faster OR more powerful (?)\n",
    "                        objective='reg:squarederror')\n",
    "    xgbr.fit(X, y)\n",
    "\n",
    "    print('Model fitted')\n",
    "\n",
    "    # Want to make predictions on every URL pair within a query, for all queries\n",
    "    # Avoid predicting on rows that were repeated above\n",
    "    # Combo of i, j query_id ensures that unique will work to prevent repeated rows\n",
    "    feat_unique = np.unique(features, axis=0)\n",
    "    X_unique = feat_unique[:, 2:-1]\n",
    "    y_pred = xgbr.predict(X_unique)\n",
    "\n",
    "    # For each query, make a prediction array (scores)\n",
    "    for qid in np.unique(X_unique[:, 0]):\n",
    "\n",
    "        # m will be the number of URLs per given query ID\n",
    "        m = int(np.sqrt(np.sum(X_unique[:, 0] == qid)))\n",
    "\n",
    "        # Save y_pred only for query of interest as y_pq, reshape in order to sum across rows\n",
    "        # Note that the default order='C' in reshape is fine (row-major)\n",
    "        # Setting order='F' will result in roughly the same result, just reversed since the \n",
    "        # learned labels correspond to (URLi - URLj)\n",
    "        y_pq = y_pred[X_unique[:, 0] == qid]\n",
    "        y_pq = y_pq.reshape(m, m, order='C')\n",
    "\n",
    "        # Apply logistic function\n",
    "        y_pq = expit(y_pq)\n",
    "\n",
    "        # Sum across rows to get 'power' of each individual training example\n",
    "        # Get order using the scores as indices\n",
    "        scores = np.sum(y_pq, axis=0)\n",
    "        order = np.argsort(scores)\n",
    "\n",
    "        # Apply order to original labels\n",
    "        y_orig = df[df.query_id == qid].label.values\n",
    "        r = y_orig[order]\n",
    "\n",
    "        # Results for entire ranking\n",
    "        print('Query %d, m=%d:' % (qid, m))\n",
    "        print('\\tNDCG@5:  %.4f' % ndcg_at_k(r=r, k=5))\n",
    "        print('\\tNDCG@10: %.4f' % ndcg_at_k(r=r, k=10))\n",
    "        print('\\tNDCG@25: %.4f' % ndcg_at_k(r=r, k=25))\n",
    "        print('\\tNDCG@50: %.4f' % ndcg_at_k(r=r, k=50))\n",
    "        print('\\tNDCG@m:  %.4f' % ndcg_at_k(r=r, k=m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = generate_dataframe('/Users/Ashtekar15/Desktop/Thesis/MGBoost/other/test_data/ranking/MSLR-WEB10K/Fold1/vali.txt', \n",
    "                           n_queries=10, \n",
    "                           seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyp_ls = [[False, False],\n",
    "          [False, True],\n",
    "          [True, False],\n",
    "          [True, True]]\n",
    "\n",
    "for hyp in hyp_ls:\n",
    "    \n",
    "    print('\\nrepeat_importance: %r, two_sided: %r, delta_features: %r' %(hyp[0], True, hyp[1]))\n",
    "    \n",
    "    my_f = generate_features(my_df, \n",
    "                             repeat_importance=hyp[0], \n",
    "                             two_sided=True, \n",
    "                             delta_features=hyp[1])\n",
    "\n",
    "    build_model(my_f, my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should record means within loop next time\n",
    "\n",
    "# repeat_importance: False, two_sided: True, delta_features: False\n",
    "print(np.mean([0.9980, 0.9954, 0.9942, 0.9851, 0.9954, 0.9944, 0.9448, 0.9915, 0.9999, 0.9979]))\n",
    "\n",
    "# repeat_importance: False, two_sided: True, delta_features: True\n",
    "print(np.mean([0.9981, 0.9885, 0.9939, 0.9861, 0.9969, 0.9925, 0.9471, 0.9932, 0.9999, 0.9972]))\n",
    "\n",
    "# repeat_importance: True, two_sided: True, delta_features: False\n",
    "print(np.mean([0.9989, 0.9930, 0.9921, 0.9930, 0.9957, .9947, 0.9461,  0.9942, 0.9999, 0.9979]))\n",
    "\n",
    "# repeat_importance: True, two_sided: True, delta_features: True\n",
    "print(np.mean([0.9978, 0.9923, 0.9908, 0.9858, 0.9968, 0.9935, 0.9460, 0.9939, 0.9999, 0.9976]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
