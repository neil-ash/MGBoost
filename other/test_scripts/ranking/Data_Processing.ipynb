{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Testing the performance of various feature configurations when using DeltaMART with the MSLR-WEB10K dataset. \n",
    "\n",
    "https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Only using a small subset of queries (10 at the moment) given that the notebook is run locally on a laptop with 8GB RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.special import expit  # Logistic function\n",
    "from rank_metrics import ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(filepath, n_queries=30, seed=1):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # For reproducible results from randomly selecting queries\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    df = pd.read_csv(filepath,\n",
    "                     sep=' ',\n",
    "                     header=None)\n",
    "    \n",
    "    # Remove last column of NaN\n",
    "    df = df.iloc[:, :-1]\n",
    "    \n",
    "    # First column: hand-labeled score, second column: query id\n",
    "    df = df.rename(columns={0: 'label', 1: 'query_id'})\n",
    "    \n",
    "    # Get random sample of queries\n",
    "    qids = df.query_id.unique()\n",
    "    qids = np.random.choice(qids, size=n_queries)\n",
    "    \n",
    "    # Only save dataframe with queries of interest\n",
    "    df = df[df.query_id.isin(qids)]\n",
    "    \n",
    "    # Save hand-labels\n",
    "    labels = df.label\n",
    "\n",
    "    # Use regex to get number after colon for every column other than label\n",
    "    features = df.iloc[:, 1:].applymap(lambda x: float(re.findall(r':(.*)', x)[0]))\n",
    "\n",
    "    # Put features and labels in same dataframe\n",
    "    df = features\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, repeat_importance, two_sided, delta_features):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    n_rows = 0\n",
    "    max_diff = 4\n",
    "    n_features = 136\n",
    "    \n",
    "    # Find max possible number of rows: n_queries * (n_urls_per_query ^ 2) * max_repeat_factor\n",
    "    for qid in df.query_id.unique():\n",
    "        urls_per_query = df[df.query_id == qid].shape[0]\n",
    "        \n",
    "        # If not repeating importance, then every query-URL pair only appears once\n",
    "        if repeat_importance:\n",
    "            n_rows += (urls_per_query ** 2) * max_diff\n",
    "        else:\n",
    "            n_rows += (urls_per_query ** 2)\n",
    "    \n",
    "    # Add extra set of columns if delta_features, + 4 for i, j, query_id, label\n",
    "    if delta_features:\n",
    "        n_columns = n_features * 3 + 4\n",
    "    else:\n",
    "        n_columns = n_features * 2 + 4\n",
    "    \n",
    "    # Create array to fill in later (faster)\n",
    "    features = np.full(shape=(n_rows, n_columns), fill_value=np.nan)\n",
    "    idx = 0\n",
    "    \n",
    "    # Compare each URL for a given query\n",
    "    for progress, qid in enumerate(df.query_id.unique()):\n",
    "        \n",
    "        # tdf: temporary dataframe, m: number of URLs in tdf\n",
    "        tdf = df[df.query_id == qid]\n",
    "        m = tdf.shape[0]\n",
    "        \n",
    "        # First URL\n",
    "        for i in range(m):\n",
    "            \n",
    "            # Two sided: feature (a, b) will be repeated later as feature (b, a)\n",
    "            if two_sided:\n",
    "                start_j = 0\n",
    "            else:\n",
    "                start_j = i\n",
    "            \n",
    "            # Second URL\n",
    "            for j in range(start_j, m):\n",
    "                \n",
    "                label_diff = tdf.label.iloc[i] - tdf.label.iloc[j]\n",
    "                \n",
    "                # Repeat importance: duplicate row |label_diff| times\n",
    "                if repeat_importance:\n",
    "                    end_k = int(abs(label_diff)) + 1\n",
    "                else:\n",
    "                    end_k = 1\n",
    "                    \n",
    "                for k in range(end_k):\n",
    "                    \n",
    "                    # Delta features: for feature (a, b), represent as (a, b, a-b)\n",
    "                    # Format: (i, j, query_id, URLi, URLj, URLi-URLj (?), label_diff)\n",
    "                    if delta_features:\n",
    "                        new_row = np.hstack((i,\n",
    "                                             j,\n",
    "                                             qid,\n",
    "                                             tdf.iloc[i, 1:-1], \n",
    "                                             tdf.iloc[j, 1:-1], \n",
    "                                             tdf.iloc[i, 1:-1] - tdf.iloc[j, 1:-1],  \n",
    "                                             label_diff))\n",
    "                    else:\n",
    "                            new_row = np.hstack((i,\n",
    "                                                 j,\n",
    "                                                 qid,\n",
    "                                                 tdf.iloc[i, 1:-1], \n",
    "                                                 tdf.iloc[j, 1:-1],  \n",
    "                                                 label_diff))\n",
    "                        \n",
    "                    features[idx] = new_row\n",
    "                    idx += 1\n",
    "\n",
    "        print(progress)\n",
    "    \n",
    "    # Originally allocated array is likely too large, only save relevant rows\n",
    "    features = features[~np.isnan(features[:, 0])]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(features, df):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # Features does not include i, j, does includes query_id\n",
    "    X = features[:, 2:-1]\n",
    "    y = features[:, -1]\n",
    "\n",
    "    # Same parameters for all calls to ensure consistency\n",
    "    xgbr = XGBRegressor(max_depth=6, \n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=100, # Change to make faster OR more powerful (?)\n",
    "                        objective='reg:squarederror')\n",
    "    xgbr.fit(X, y)\n",
    "\n",
    "    print('Model fitted')\n",
    "\n",
    "    # Want to make predictions on every URL pair within a query, for all queries\n",
    "    # Avoid predicting on rows that were repeated above\n",
    "    # Combo of i, j query_id ensures that unique will work to prevent repeated rows\n",
    "    feat_unique = np.unique(features, axis=0)\n",
    "    X_unique = feat_unique[:, 2:-1]\n",
    "    y_pred = xgbr.predict(X_unique)\n",
    "\n",
    "    # For each query, make a prediction array (scores)\n",
    "    for qid in np.unique(X_unique[:, 0]):\n",
    "\n",
    "        # m will be the number of URLs per given query ID\n",
    "        m = int(np.sqrt(np.sum(X_unique[:, 0] == qid)))\n",
    "\n",
    "        # Save y_pred only for query of interest as y_pq, reshape in order to sum across rows\n",
    "        # Note that the default order='C' in reshape is fine (row-major)\n",
    "        # Setting order='F' will result in roughly the same result, just reversed since the \n",
    "        # learned labels correspond to (URLi - URLj)\n",
    "        y_pq = y_pred[X_unique[:, 0] == qid]\n",
    "        y_pq = y_pq.reshape(m, m, order='C')\n",
    "\n",
    "        # Apply logistic function\n",
    "        y_pq = expit(y_pq)\n",
    "\n",
    "        # Sum across rows to get 'power' of each individual training example\n",
    "        # Get order using the scores as indices\n",
    "        scores = np.sum(y_pq, axis=0)\n",
    "        order = np.argsort(scores)\n",
    "\n",
    "        # Apply order to original labels\n",
    "        y_orig = df[df.query_id == qid].label.values\n",
    "        r = y_orig[order]\n",
    "\n",
    "        # Results for entire ranking\n",
    "        print('Query %d, m=%d:' % (qid, m))\n",
    "        print('\\tNDCG@5:  %.4f' % ndcg_at_k(r=r, k=5))\n",
    "        print('\\tNDCG@10: %.4f' % ndcg_at_k(r=r, k=10))\n",
    "        print('\\tNDCG@25: %.4f' % ndcg_at_k(r=r, k=25))\n",
    "        print('\\tNDCG@50: %.4f' % ndcg_at_k(r=r, k=50))\n",
    "        print('\\tNDCG@m:  %.4f' % ndcg_at_k(r=r, k=m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = generate_dataframe('/Users/Ashtekar15/Desktop/Thesis/MGBoost/other/test_data/ranking/MSLR-WEB10K/Fold1/vali.txt', \n",
    "                           n_queries=10, \n",
    "                           seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "repeat_importance: False, two_sided: True, delta_features: False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashtekar15/anaconda3/lib/python3.6/site-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted\n",
      "Query 3535, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9884\n",
      "\tNDCG@50: 0.9984\n",
      "\tNDCG@m:  0.9980\n",
      "Query 10735, m=89:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9847\n",
      "\tNDCG@50: 0.9958\n",
      "\tNDCG@m:  0.9954\n",
      "Query 12715, m=91:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9984\n",
      "\tNDCG@25: 0.9730\n",
      "\tNDCG@50: 0.9787\n",
      "\tNDCG@m:  0.9942\n",
      "Query 13585, m=156:\n",
      "\tNDCG@5:  0.9181\n",
      "\tNDCG@10: 0.9775\n",
      "\tNDCG@25: 0.9574\n",
      "\tNDCG@50: 0.9662\n",
      "\tNDCG@m:  0.9851\n",
      "Query 14410, m=150:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9932\n",
      "\tNDCG@50: 0.9948\n",
      "\tNDCG@m:  0.9954\n",
      "Query 15925, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9969\n",
      "\tNDCG@50: 0.9783\n",
      "\tNDCG@m:  0.9944\n",
      "Query 16450, m=77:\n",
      "\tNDCG@5:  0.9440\n",
      "\tNDCG@10: 0.8609\n",
      "\tNDCG@25: 0.9217\n",
      "\tNDCG@50: 0.9448\n",
      "\tNDCG@m:  0.9448\n",
      "Query 25045, m=46:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9942\n",
      "\tNDCG@25: 0.9681\n",
      "\tNDCG@50: 0.9915\n",
      "\tNDCG@m:  0.9915\n",
      "Query 26875, m=202:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 1.0000\n",
      "\tNDCG@50: 1.0000\n",
      "\tNDCG@m:  0.9999\n",
      "Query 28990, m=151:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9986\n",
      "\tNDCG@50: 0.9897\n",
      "\tNDCG@m:  0.9979\n",
      "\n",
      "repeat_importance: False, two_sided: True, delta_features: True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Model fitted\n",
      "Query 3535, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9883\n",
      "\tNDCG@50: 0.9988\n",
      "\tNDCG@m:  0.9981\n",
      "Query 10735, m=89:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9793\n",
      "\tNDCG@25: 0.9659\n",
      "\tNDCG@50: 0.9887\n",
      "\tNDCG@m:  0.9885\n",
      "Query 12715, m=91:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9832\n",
      "\tNDCG@25: 0.9801\n",
      "\tNDCG@50: 0.9785\n",
      "\tNDCG@m:  0.9939\n",
      "Query 13585, m=156:\n",
      "\tNDCG@5:  0.9493\n",
      "\tNDCG@10: 0.9812\n",
      "\tNDCG@25: 0.9687\n",
      "\tNDCG@50: 0.9623\n",
      "\tNDCG@m:  0.9861\n",
      "Query 14410, m=150:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9820\n",
      "\tNDCG@50: 0.9966\n",
      "\tNDCG@m:  0.9969\n",
      "Query 15925, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9844\n",
      "\tNDCG@50: 0.9683\n",
      "\tNDCG@m:  0.9925\n",
      "Query 16450, m=77:\n",
      "\tNDCG@5:  0.9440\n",
      "\tNDCG@10: 0.8609\n",
      "\tNDCG@25: 0.9236\n",
      "\tNDCG@50: 0.9471\n",
      "\tNDCG@m:  0.9471\n",
      "Query 25045, m=46:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9985\n",
      "\tNDCG@25: 0.9816\n",
      "\tNDCG@50: 0.9932\n",
      "\tNDCG@m:  0.9932\n",
      "Query 26875, m=202:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 1.0000\n",
      "\tNDCG@50: 1.0000\n",
      "\tNDCG@m:  0.9999\n",
      "Query 28990, m=151:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9982\n",
      "\tNDCG@50: 0.9940\n",
      "\tNDCG@m:  0.9972\n",
      "\n",
      "repeat_importance: True, two_sided: True, delta_features: False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Model fitted\n",
      "Query 3535, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9879\n",
      "\tNDCG@50: 0.9991\n",
      "\tNDCG@m:  0.9989\n",
      "Query 10735, m=89:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9817\n",
      "\tNDCG@50: 0.9789\n",
      "\tNDCG@m:  0.9930\n",
      "Query 12715, m=91:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9664\n",
      "\tNDCG@25: 0.9770\n",
      "\tNDCG@50: 0.9818\n",
      "\tNDCG@m:  0.9921\n",
      "Query 13585, m=156:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9801\n",
      "\tNDCG@50: 0.9767\n",
      "\tNDCG@m:  0.9930\n",
      "Query 14410, m=150:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9935\n",
      "\tNDCG@50: 0.9951\n",
      "\tNDCG@m:  0.9957\n",
      "Query 15925, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9984\n",
      "\tNDCG@50: 0.9798\n",
      "\tNDCG@m:  0.9947\n",
      "Query 16450, m=77:\n",
      "\tNDCG@5:  0.9440\n",
      "\tNDCG@10: 0.8609\n",
      "\tNDCG@25: 0.9248\n",
      "\tNDCG@50: 0.9461\n",
      "\tNDCG@m:  0.9461\n",
      "Query 25045, m=46:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9985\n",
      "\tNDCG@25: 0.9716\n",
      "\tNDCG@50: 0.9942\n",
      "\tNDCG@m:  0.9942\n",
      "Query 26875, m=202:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 1.0000\n",
      "\tNDCG@50: 1.0000\n",
      "\tNDCG@m:  0.9999\n",
      "Query 28990, m=151:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9984\n",
      "\tNDCG@50: 0.9941\n",
      "\tNDCG@m:  0.9979\n",
      "\n",
      "repeat_importance: True, two_sided: True, delta_features: True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Model fitted\n",
      "Query 3535, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9877\n",
      "\tNDCG@50: 0.9987\n",
      "\tNDCG@m:  0.9978\n",
      "Query 10735, m=89:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9596\n",
      "\tNDCG@50: 0.9923\n",
      "\tNDCG@m:  0.9923\n",
      "Query 12715, m=91:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9519\n",
      "\tNDCG@25: 0.9680\n",
      "\tNDCG@50: 0.9754\n",
      "\tNDCG@m:  0.9908\n",
      "Query 13585, m=156:\n",
      "\tNDCG@5:  0.9543\n",
      "\tNDCG@10: 0.9857\n",
      "\tNDCG@25: 0.9679\n",
      "\tNDCG@50: 0.9615\n",
      "\tNDCG@m:  0.9858\n",
      "Query 14410, m=150:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9958\n",
      "\tNDCG@50: 0.9968\n",
      "\tNDCG@m:  0.9968\n",
      "Query 15925, m=131:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 0.9969\n",
      "\tNDCG@50: 0.9690\n",
      "\tNDCG@m:  0.9935\n",
      "Query 16450, m=77:\n",
      "\tNDCG@5:  0.9440\n",
      "\tNDCG@10: 0.8609\n",
      "\tNDCG@25: 0.9223\n",
      "\tNDCG@50: 0.9460\n",
      "\tNDCG@m:  0.9460\n",
      "Query 25045, m=46:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9985\n",
      "\tNDCG@25: 0.9822\n",
      "\tNDCG@50: 0.9939\n",
      "\tNDCG@m:  0.9939\n",
      "Query 26875, m=202:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 1.0000\n",
      "\tNDCG@25: 1.0000\n",
      "\tNDCG@50: 1.0000\n",
      "\tNDCG@m:  0.9999\n",
      "Query 28990, m=151:\n",
      "\tNDCG@5:  1.0000\n",
      "\tNDCG@10: 0.9852\n",
      "\tNDCG@25: 0.9979\n",
      "\tNDCG@50: 0.9936\n",
      "\tNDCG@m:  0.9976\n"
     ]
    }
   ],
   "source": [
    "hyp_ls = [[False, False],\n",
    "          [False, True],\n",
    "          [True, False],\n",
    "          [True, True]]\n",
    "\n",
    "for hyp in hyp_ls:\n",
    "    \n",
    "    print('\\nrepeat_importance: %r, two_sided: %r, delta_features: %r' %(hyp[0], True, hyp[1]))\n",
    "    \n",
    "    my_f = generate_features(my_df, \n",
    "                             repeat_importance=hyp[0], \n",
    "                             two_sided=True, \n",
    "                             delta_features=hyp[1])\n",
    "\n",
    "    build_model(my_f, my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98966\n",
      "0.98934\n",
      "0.99055\n",
      "0.9894400000000001\n"
     ]
    }
   ],
   "source": [
    "# Should record means within loop next time\n",
    "\n",
    "# repeat_importance: False, two_sided: True, delta_features: False\n",
    "print(np.mean([0.9980, 0.9954, 0.9942, 0.9851, 0.9954, 0.9944, 0.9448, 0.9915, 0.9999, 0.9979]))\n",
    "\n",
    "# repeat_importance: False, two_sided: True, delta_features: True\n",
    "print(np.mean([0.9981, 0.9885, 0.9939, 0.9861, 0.9969, 0.9925, 0.9471, 0.9932, 0.9999, 0.9972]))\n",
    "\n",
    "# repeat_importance: True, two_sided: True, delta_features: False\n",
    "print(np.mean([0.9989, 0.9930, 0.9921, 0.9930, 0.9957, .9947, 0.9461,  0.9942, 0.9999, 0.9979]))\n",
    "\n",
    "# repeat_importance: True, two_sided: True, delta_features: True\n",
    "print(np.mean([0.9978, 0.9923, 0.9908, 0.9858, 0.9968, 0.9935, 0.9460, 0.9939, 0.9999, 0.9976]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much difference in performance across different feature configurations. To better illustrate differences, I should "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
