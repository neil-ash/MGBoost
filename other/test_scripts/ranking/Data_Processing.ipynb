{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(filepath, n_queries=30, seed=1):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # For reproducible results from randomly selecting queries\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    df = pd.read_csv(filepath,\n",
    "                       sep=' ',\n",
    "                       header=None)\n",
    "    \n",
    "    # Remove last column of NaN\n",
    "    df = df.iloc[:, :-1]\n",
    "    \n",
    "    # First column: hand-labeled score, second column: query id\n",
    "    df = df.rename(columns={0: 'label', 1: 'query_id'})\n",
    "    \n",
    "    # Get random sample of queries\n",
    "    qids = df.query_id.unique()\n",
    "    qids = np.random.choice(qids, size=n_queries)\n",
    "    \n",
    "    # Only save dataframe with queries of interest\n",
    "    df = df[df.query_id.isin(qids)]\n",
    "    \n",
    "    # Save hand-labels\n",
    "    labels = df.label\n",
    "\n",
    "    # Use regex to get number after colon for every column other than label\n",
    "    features = df.iloc[:, 1:].applymap(lambda x: float(re.findall(r':(.*)', x)[0]))\n",
    "\n",
    "    # Put features and labels in same dataframe\n",
    "    df = features\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, repeat_importance, two_sided, delta_features):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    n_rows = 0\n",
    "    max_diff = 4\n",
    "    n_features = 136\n",
    "    \n",
    "    # Find max number of rows: n_queries * n_urls_per_query ^ 2 * max_repeat_factor\n",
    "    for qid in df.query_id.unique():\n",
    "        urls_per_query = df[df.query_id == qid].shape[0]\n",
    "        n_rows += (urls_per_query ** 2) * max_diff\n",
    "    \n",
    "    # Add extra set of columns if delta_features, + 2 for query_id and label (score)\n",
    "    if delta_features:\n",
    "        n_columns = n_features * 3 + 2\n",
    "    else:\n",
    "        n_columns = n_features * 2 + 2\n",
    "    \n",
    "    # Create array to fill in later (faster)\n",
    "    features = np.full(shape=(n_rows, n_columns), fill_value=np.nan)\n",
    "    idx = 0\n",
    "    \n",
    "    # Compare each URL for a given query\n",
    "    for progress, qid in enumerate(df.query_id.unique()):\n",
    "        \n",
    "        # tdf: temporary dataframe, m: number of URLs in tdf\n",
    "        tdf = df[df.query_id == qid]\n",
    "        m = tdf.shape[0]\n",
    "        \n",
    "        # First URL\n",
    "        for i in range(m):\n",
    "            \n",
    "            if two_sided:\n",
    "                start_j = 0\n",
    "            else:\n",
    "                start_j = i\n",
    "            \n",
    "            # Second URL\n",
    "            for j in range(start_j, m):\n",
    "                \n",
    "                label_diff = tdf.label.iloc[i] - tdf.label.iloc[j]\n",
    "                \n",
    "                if repeat_importance:\n",
    "                    end_k = 1\n",
    "                else:\n",
    "                    end_k = int(abs(label_diff)) + 1\n",
    "                    \n",
    "                for k in range(end_k):\n",
    "                    \n",
    "                    if delta_features:\n",
    "                        new_row = np.hstack((tdf.iloc[i, 1:-1], \n",
    "                                             tdf.iloc[j, 1:-1], \n",
    "                                             tdf.iloc[i, 1:-1] - tdf.iloc[j, 1:-1], \n",
    "                                             qid, \n",
    "                                             label_diff))\n",
    "                    else:\n",
    "                            new_row = np.hstack((tdf.iloc[i, 1:-1], \n",
    "                                                 tdf.iloc[j, 1:-1], \n",
    "                                                 qid, \n",
    "                                                 label_diff))\n",
    "                        \n",
    "                    features[idx] = new_row\n",
    "                    idx += 1\n",
    "\n",
    "        print(progress)\n",
    "        \n",
    "    features = features[~np.isnan(features[:, 0])]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = generate_dataframe(path + 'vali.txt', n_queries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_f = generate_features(my_df, repeat_importance=False, two_sided=False, delta_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_f[:, :-2]\n",
    "y = my_f[:, -1]\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "xgbr = XGBRegressor(max_depth=6, \n",
    "                    learning_rate=0.1,\n",
    "                    n_estimators=100,\n",
    "                    objective='reg:squarederror')\n",
    "xgbr.fit(X, y)\n",
    "mean_absolute_error(y, xgbr.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
